{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from vowpalwabbit.DFtoVW import DFtoVW\n",
    "from vowpalwabbit.pyvw import vw\n",
    "\n",
    "# Graphical\n",
    "SUPTITLE_FONTSIZE = 20\n",
    "SUPTITLE_FONTWEIGHT = \"bold\"\n",
    "TITLE_FONTSIZE = 15\n",
    "\n",
    "from utils import default_feature_str, default_feature_str, get_test_example, get_vw_examples, get_training_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79020, 122)\n"
     ]
    }
   ],
   "source": [
    "feature_names =[\"Num token\",\"Num char\",\"Avg word length\",\"Num ADJ\",\"Num ADP\",\"Num ADV\",\"Num AUX\",\"Num CCONJ\",\"Num DET\",\"Num INTJ\",\"Num NOUN\",\"Num NUM\",\"Num PART\",\"Num PRON\",\"Num PROPN\",\"Num PUNCT\",\"Num SCONJ\",\"Num SYM\",\"Num VERB\",\"Num X\",\"Num LOC\",\"Num MISC\",\"Num ORG\",\"Num PER\",\"Num Abbr=Yes\",\"Num Case=Acc\",\"Num Case=Nom\",\"Num Definite=Def\",\"Num Definite=Ind\",\"Num Degree=Cmp\",\"Num Degree=Pos\",\"Num Degree=Sup\",\"Num Foreign=Yes\",\"Num Gender=Fem\",\"Num Gender=Masc\",\"Num Gender=Neut\",\"Num Mood=Imp\",\"Num Mood=Ind\",\"Num NumForm=Digit\",\"Num NumForm=Word\",\"Num NumType=Card\",\"Num NumType=Mult\",\"Num NumType=Ord\",\"Num Number=Plur\",\"Num Number=Sing\",\"Num Person=1\",\"Num Person=2\",\"Num Person=3\",\"Num Polarity=Neg\",\"Num Poss=Yes\",\"Num PronType=Art\",\"Num PronType=Dem\",\"Num PronType=Int\",\"Num PronType=Prs\",\"Num PronType=Rel\",\"Num Reflex=Yes\",\"Num Tense=Past\",\"Num Tense=Pres\",\"Num VerbForm=Fin\",\"Num VerbForm=Ger\",\"Num VerbForm=Inf\",\"Num VerbForm=Part\",\"Num Voice=Pass\",\"Num Style=Expr\",\"Num NumForm=Roman\",\"Num Mood=Cnd\",\"Num Mood=Sub\",\"Num Number[psor]=Plur\",\"Num Number[psor]=Sing\",\"Num Person[psor]=1\",\"Num Person[psor]=2\",\"Num Person[psor]=3\",\"Num PronType=Exc\",\"Num PronType=Ind\",\"Num PronType=Neg\",\"Num Tense=Fut\",\"Num Tense=Imp\",\"Num Typo=Yes\",\"Num Case=Dat\",\"Num Case=Gen\",\"Num Gender[psor]=Masc,Neut\",\"Num Animacy=Anim\",\"Num Animacy=Inan\",\"Num Aspect=Imp\",\"Num Aspect=Perf\",\"Num Case=Ins\",\"Num Case=Loc\",\"Num Variant=Short\",\"Num VerbForm=Conv\",\"Num Voice=Act\",\"Num Voice=Mid\",\"Num AdpType=Comprep\",\"Num AdpType=Prep\",\"Num AdpType=Voc\",\"Num Case=Voc\",\"Num ConjType=Oper\",\"Num Gender=Fem,Masc\",\"Num Gender=Fem,Neut\",\"Num Gender=Masc,Neut\",\"Num Gender[psor]=Fem\",\"Num Gender[psor]=Masc\",\"Num Hyph=Yes\",\"Num NameType=Com\",\"Num NameType=Geo\",\"Num NameType=Giv\",\"Num NameType=Nat\",\"Num NameType=Sur\",\"Num NumType=Frac\",\"Num NumType=Sets\",\"Num NumValue=1\",\"Num NumValue=1,2,3\",\"Num Number=Dual\",\"Num Number=Plur,Sing\",\"Num Polarity=Pos\",\"Num PrepCase=Npr\",\"Num PrepCase=Pre\",\"Num PronType=Emp\",\"Num PronType=Int,Rel\",\"Num PronType=Tot\",\"Num Style=Arch\",\"Num Style=Coll\",\n",
    "        ]\n",
    "        \n",
    "X_train = np.load(\"./data/X_train.npy\")\n",
    "y_train = np.load(\"./data/y_train.npy\")\n",
    "X_test = np.load(\"./data/X_test.npy\")\n",
    "y_test = np.load(\"./data/y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 01-24 01:55:20] {2007} INFO - task = regression\n",
      "[flaml.automl: 01-24 01:55:20] {2009} INFO - Data split method: uniform\n",
      "[flaml.automl: 01-24 01:55:20] {2013} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 01-24 01:55:20] {2113} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 01-24 01:55:20] {2170} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl: 01-24 01:55:20] {2437} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 01-24 01:55:20] {2550} INFO - Estimated sufficient time budget=1420s. Estimated necessary time budget=12s.\n",
      "[flaml.automl: 01-24 01:55:20] {2597} INFO -  at 0.1s,\testimator lgbm's best error=0.9924,\tbest estimator lgbm's best error=0.9924\n",
      "[flaml.automl: 01-24 01:55:20] {2437} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 01-24 01:55:20] {2597} INFO -  at 0.1s,\testimator lgbm's best error=0.9924,\tbest estimator lgbm's best error=0.9924\n",
      "[flaml.automl: 01-24 01:55:20] {2437} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 01-24 01:55:20] {2597} INFO -  at 0.1s,\testimator lgbm's best error=0.9857,\tbest estimator lgbm's best error=0.9857\n",
      "[flaml.automl: 01-24 01:55:20] {2437} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl: 01-24 01:55:20] {2597} INFO -  at 0.2s,\testimator xgboost's best error=1.2060,\tbest estimator lgbm's best error=0.9857\n",
      "[flaml.automl: 01-24 01:55:20] {2437} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl: 01-24 01:55:20] {2597} INFO -  at 0.2s,\testimator lgbm's best error=0.9773,\tbest estimator lgbm's best error=0.9773\n",
      "[flaml.automl: 01-24 01:55:20] {2437} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl: 01-24 01:55:20] {2597} INFO -  at 0.3s,\testimator lgbm's best error=0.9773,\tbest estimator lgbm's best error=0.9773\n",
      "[flaml.automl: 01-24 01:55:20] {2437} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 01-24 01:55:20] {2597} INFO -  at 0.3s,\testimator lgbm's best error=0.9773,\tbest estimator lgbm's best error=0.9773\n",
      "[flaml.automl: 01-24 01:55:20] {2437} INFO - iteration 7, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:20] {2597} INFO -  at 0.3s,\testimator extra_tree's best error=0.9855,\tbest estimator lgbm's best error=0.9773\n",
      "[flaml.automl: 01-24 01:55:20] {2437} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 01-24 01:55:20] {2597} INFO -  at 0.3s,\testimator lgbm's best error=0.9773,\tbest estimator lgbm's best error=0.9773\n",
      "[flaml.automl: 01-24 01:55:20] {2437} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 01-24 01:55:20] {2597} INFO -  at 0.3s,\testimator lgbm's best error=0.9767,\tbest estimator lgbm's best error=0.9767\n",
      "[flaml.automl: 01-24 01:55:20] {2437} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl: 01-24 01:55:20] {2597} INFO -  at 0.4s,\testimator xgboost's best error=1.2060,\tbest estimator lgbm's best error=0.9767\n",
      "[flaml.automl: 01-24 01:55:20] {2437} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 01-24 01:55:20] {2597} INFO -  at 0.4s,\testimator xgboost's best error=1.0280,\tbest estimator lgbm's best error=0.9767\n",
      "[flaml.automl: 01-24 01:55:20] {2437} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:20] {2597} INFO -  at 0.4s,\testimator extra_tree's best error=0.9743,\tbest estimator extra_tree's best error=0.9743\n",
      "[flaml.automl: 01-24 01:55:20] {2437} INFO - iteration 13, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:20] {2597} INFO -  at 0.5s,\testimator extra_tree's best error=0.9743,\tbest estimator extra_tree's best error=0.9743\n",
      "[flaml.automl: 01-24 01:55:20] {2437} INFO - iteration 14, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:20] {2597} INFO -  at 0.6s,\testimator extra_tree's best error=0.9573,\tbest estimator extra_tree's best error=0.9573\n",
      "[flaml.automl: 01-24 01:55:20] {2437} INFO - iteration 15, current learner rf\n",
      "[flaml.automl: 01-24 01:55:20] {2597} INFO -  at 0.6s,\testimator rf's best error=0.9886,\tbest estimator extra_tree's best error=0.9573\n",
      "[flaml.automl: 01-24 01:55:20] {2437} INFO - iteration 16, current learner rf\n",
      "[flaml.automl: 01-24 01:55:20] {2597} INFO -  at 0.7s,\testimator rf's best error=0.9779,\tbest estimator extra_tree's best error=0.9573\n",
      "[flaml.automl: 01-24 01:55:20] {2437} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:20] {2597} INFO -  at 0.8s,\testimator extra_tree's best error=0.9565,\tbest estimator extra_tree's best error=0.9565\n",
      "[flaml.automl: 01-24 01:55:20] {2437} INFO - iteration 18, current learner rf\n",
      "[flaml.automl: 01-24 01:55:20] {2597} INFO -  at 0.9s,\testimator rf's best error=0.9779,\tbest estimator extra_tree's best error=0.9565\n",
      "[flaml.automl: 01-24 01:55:20] {2437} INFO - iteration 19, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:21] {2597} INFO -  at 0.9s,\testimator extra_tree's best error=0.9565,\tbest estimator extra_tree's best error=0.9565\n",
      "[flaml.automl: 01-24 01:55:21] {2437} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl: 01-24 01:55:21] {2597} INFO -  at 1.0s,\testimator xgboost's best error=0.9795,\tbest estimator extra_tree's best error=0.9565\n",
      "[flaml.automl: 01-24 01:55:21] {2437} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl: 01-24 01:55:21] {2597} INFO -  at 1.0s,\testimator xgboost's best error=0.9795,\tbest estimator extra_tree's best error=0.9565\n",
      "[flaml.automl: 01-24 01:55:21] {2437} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl: 01-24 01:55:21] {2597} INFO -  at 1.0s,\testimator xgboost's best error=0.9795,\tbest estimator extra_tree's best error=0.9565\n",
      "[flaml.automl: 01-24 01:55:21] {2437} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl: 01-24 01:55:21] {2597} INFO -  at 1.1s,\testimator xgboost's best error=0.9795,\tbest estimator extra_tree's best error=0.9565\n",
      "[flaml.automl: 01-24 01:55:21] {2437} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:21] {2597} INFO -  at 1.2s,\testimator extra_tree's best error=0.9565,\tbest estimator extra_tree's best error=0.9565\n",
      "[flaml.automl: 01-24 01:55:21] {2437} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:21] {2597} INFO -  at 1.3s,\testimator extra_tree's best error=0.9565,\tbest estimator extra_tree's best error=0.9565\n",
      "[flaml.automl: 01-24 01:55:21] {2437} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl: 01-24 01:55:21] {2597} INFO -  at 1.3s,\testimator xgboost's best error=0.9795,\tbest estimator extra_tree's best error=0.9565\n",
      "[flaml.automl: 01-24 01:55:21] {2437} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:21] {2597} INFO -  at 1.5s,\testimator extra_tree's best error=0.9565,\tbest estimator extra_tree's best error=0.9565\n",
      "[flaml.automl: 01-24 01:55:21] {2437} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:21] {2597} INFO -  at 1.8s,\testimator extra_tree's best error=0.8980,\tbest estimator extra_tree's best error=0.8980\n",
      "[flaml.automl: 01-24 01:55:21] {2437} INFO - iteration 29, current learner catboost\n",
      "[flaml.automl: 01-24 01:55:22] {2597} INFO -  at 2.2s,\testimator catboost's best error=0.9588,\tbest estimator extra_tree's best error=0.8980\n",
      "[flaml.automl: 01-24 01:55:22] {2437} INFO - iteration 30, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:22] {2597} INFO -  at 2.5s,\testimator extra_tree's best error=0.8846,\tbest estimator extra_tree's best error=0.8846\n",
      "[flaml.automl: 01-24 01:55:22] {2437} INFO - iteration 31, current learner catboost\n",
      "[flaml.automl: 01-24 01:55:23] {2597} INFO -  at 3.2s,\testimator catboost's best error=0.9346,\tbest estimator extra_tree's best error=0.8846\n",
      "[flaml.automl: 01-24 01:55:23] {2437} INFO - iteration 32, current learner rf\n",
      "[flaml.automl: 01-24 01:55:23] {2597} INFO -  at 3.3s,\testimator rf's best error=0.9686,\tbest estimator extra_tree's best error=0.8846\n",
      "[flaml.automl: 01-24 01:55:23] {2437} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl: 01-24 01:55:25] {2597} INFO -  at 5.1s,\testimator xgboost's best error=0.9737,\tbest estimator extra_tree's best error=0.8846\n",
      "[flaml.automl: 01-24 01:55:25] {2437} INFO - iteration 34, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:25] {2597} INFO -  at 5.5s,\testimator extra_tree's best error=0.8846,\tbest estimator extra_tree's best error=0.8846\n",
      "[flaml.automl: 01-24 01:55:25] {2437} INFO - iteration 35, current learner rf\n",
      "[flaml.automl: 01-24 01:55:25] {2597} INFO -  at 5.7s,\testimator rf's best error=0.9686,\tbest estimator extra_tree's best error=0.8846\n",
      "[flaml.automl: 01-24 01:55:25] {2437} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:26] {2597} INFO -  at 6.0s,\testimator extra_tree's best error=0.8846,\tbest estimator extra_tree's best error=0.8846\n",
      "[flaml.automl: 01-24 01:55:26] {2437} INFO - iteration 37, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:26] {2597} INFO -  at 6.7s,\testimator extra_tree's best error=0.8515,\tbest estimator extra_tree's best error=0.8515\n",
      "[flaml.automl: 01-24 01:55:26] {2437} INFO - iteration 38, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:27] {2597} INFO -  at 7.1s,\testimator extra_tree's best error=0.8515,\tbest estimator extra_tree's best error=0.8515\n",
      "[flaml.automl: 01-24 01:55:27] {2437} INFO - iteration 39, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:28] {2597} INFO -  at 8.1s,\testimator extra_tree's best error=0.8515,\tbest estimator extra_tree's best error=0.8515\n",
      "[flaml.automl: 01-24 01:55:28] {2437} INFO - iteration 40, current learner catboost\n",
      "[flaml.automl: 01-24 01:55:28] {2597} INFO -  at 8.4s,\testimator catboost's best error=0.9346,\tbest estimator extra_tree's best error=0.8515\n",
      "[flaml.automl: 01-24 01:55:28] {2437} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:29] {2597} INFO -  at 8.9s,\testimator extra_tree's best error=0.8515,\tbest estimator extra_tree's best error=0.8515\n",
      "[flaml.automl: 01-24 01:55:29] {2437} INFO - iteration 42, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:29] {2597} INFO -  at 9.6s,\testimator extra_tree's best error=0.8450,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:29] {2437} INFO - iteration 43, current learner xgb_limitdepth\n",
      "[flaml.automl: 01-24 01:55:34] {2597} INFO -  at 14.1s,\testimator xgb_limitdepth's best error=0.9462,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:34] {2437} INFO - iteration 44, current learner lgbm\n",
      "[flaml.automl: 01-24 01:55:34] {2597} INFO -  at 14.1s,\testimator lgbm's best error=0.9681,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:34] {2437} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:35] {2597} INFO -  at 15.1s,\testimator extra_tree's best error=0.8450,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:35] {2437} INFO - iteration 46, current learner xgb_limitdepth\n",
      "[flaml.automl: 01-24 01:55:35] {2597} INFO -  at 15.2s,\testimator xgb_limitdepth's best error=0.9462,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:35] {2437} INFO - iteration 47, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:35] {2597} INFO -  at 15.7s,\testimator extra_tree's best error=0.8450,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:35] {2437} INFO - iteration 48, current learner lgbm\n",
      "[flaml.automl: 01-24 01:55:35] {2597} INFO -  at 15.7s,\testimator lgbm's best error=0.9681,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:35] {2437} INFO - iteration 49, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:36] {2597} INFO -  at 16.6s,\testimator extra_tree's best error=0.8450,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:36] {2437} INFO - iteration 50, current learner lgbm\n",
      "[flaml.automl: 01-24 01:55:36] {2597} INFO -  at 16.8s,\testimator lgbm's best error=0.9449,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:36] {2437} INFO - iteration 51, current learner lgbm\n",
      "[flaml.automl: 01-24 01:55:37] {2597} INFO -  at 17.0s,\testimator lgbm's best error=0.9449,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:37] {2437} INFO - iteration 52, current learner xgb_limitdepth\n",
      "[flaml.automl: 01-24 01:55:37] {2597} INFO -  at 17.1s,\testimator xgb_limitdepth's best error=0.9462,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:37] {2437} INFO - iteration 53, current learner rf\n",
      "[flaml.automl: 01-24 01:55:37] {2597} INFO -  at 17.2s,\testimator rf's best error=0.9686,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:37] {2437} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl: 01-24 01:55:37] {2597} INFO -  at 17.2s,\testimator lgbm's best error=0.9449,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:37] {2437} INFO - iteration 55, current learner lgbm\n",
      "[flaml.automl: 01-24 01:55:37] {2597} INFO -  at 17.3s,\testimator lgbm's best error=0.9449,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:37] {2437} INFO - iteration 56, current learner lgbm\n",
      "[flaml.automl: 01-24 01:55:37] {2597} INFO -  at 17.6s,\testimator lgbm's best error=0.9237,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:37] {2437} INFO - iteration 57, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:38] {2597} INFO -  at 18.2s,\testimator extra_tree's best error=0.8450,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:38] {2437} INFO - iteration 58, current learner lgbm\n",
      "[flaml.automl: 01-24 01:55:39] {2597} INFO -  at 18.9s,\testimator lgbm's best error=0.9237,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:39] {2437} INFO - iteration 59, current learner catboost\n",
      "[flaml.automl: 01-24 01:55:39] {2597} INFO -  at 19.7s,\testimator catboost's best error=0.9346,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:39] {2437} INFO - iteration 60, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:40] {2597} INFO -  at 20.4s,\testimator extra_tree's best error=0.8450,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:40] {2437} INFO - iteration 61, current learner lgbm\n",
      "[flaml.automl: 01-24 01:55:42] {2597} INFO -  at 22.8s,\testimator lgbm's best error=0.9237,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:42] {2437} INFO - iteration 62, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:43] {2597} INFO -  at 23.6s,\testimator extra_tree's best error=0.8450,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:43] {2437} INFO - iteration 63, current learner rf\n",
      "[flaml.automl: 01-24 01:55:43] {2597} INFO -  at 23.8s,\testimator rf's best error=0.9686,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:43] {2437} INFO - iteration 64, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:44] {2597} INFO -  at 24.6s,\testimator extra_tree's best error=0.8450,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:44] {2437} INFO - iteration 65, current learner xgb_limitdepth\n",
      "[flaml.automl: 01-24 01:55:45] {2597} INFO -  at 25.6s,\testimator xgb_limitdepth's best error=0.9462,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:45] {2437} INFO - iteration 66, current learner rf\n",
      "[flaml.automl: 01-24 01:55:45] {2597} INFO -  at 25.7s,\testimator rf's best error=0.9686,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:45] {2437} INFO - iteration 67, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:46] {2597} INFO -  at 26.1s,\testimator extra_tree's best error=0.8450,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:46] {2437} INFO - iteration 68, current learner xgb_limitdepth\n",
      "[flaml.automl: 01-24 01:55:46] {2597} INFO -  at 26.2s,\testimator xgb_limitdepth's best error=0.9462,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:46] {2437} INFO - iteration 69, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:47] {2597} INFO -  at 27.4s,\testimator extra_tree's best error=0.8450,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:47] {2437} INFO - iteration 70, current learner lgbm\n",
      "[flaml.automl: 01-24 01:55:47] {2597} INFO -  at 27.7s,\testimator lgbm's best error=0.8629,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:47] {2437} INFO - iteration 71, current learner xgboost\n",
      "[flaml.automl: 01-24 01:55:47] {2597} INFO -  at 27.8s,\testimator xgboost's best error=0.9737,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:47] {2437} INFO - iteration 72, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:48] {2597} INFO -  at 28.2s,\testimator extra_tree's best error=0.8450,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:48] {2437} INFO - iteration 73, current learner catboost\n",
      "[flaml.automl: 01-24 01:55:48] {2597} INFO -  at 28.7s,\testimator catboost's best error=0.9346,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:48] {2437} INFO - iteration 74, current learner xgb_limitdepth\n",
      "[flaml.automl: 01-24 01:55:48] {2597} INFO -  at 28.8s,\testimator xgb_limitdepth's best error=0.9462,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:48] {2437} INFO - iteration 75, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:55:49] {2597} INFO -  at 29.6s,\testimator extra_tree's best error=0.8450,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:49] {2437} INFO - iteration 76, current learner xgb_limitdepth\n",
      "[flaml.automl: 01-24 01:55:52] {2597} INFO -  at 32.3s,\testimator xgb_limitdepth's best error=0.9462,\tbest estimator extra_tree's best error=0.8450\n",
      "[flaml.automl: 01-24 01:55:52] {2437} INFO - iteration 77, current learner lgbm\n",
      "[flaml.automl: 01-24 01:55:55] {2597} INFO -  at 35.4s,\testimator lgbm's best error=0.8423,\tbest estimator lgbm's best error=0.8423\n",
      "[flaml.automl: 01-24 01:55:55] {2437} INFO - iteration 78, current learner lgbm\n",
      "[flaml.automl: 01-24 01:55:55] {2597} INFO -  at 35.7s,\testimator lgbm's best error=0.8423,\tbest estimator lgbm's best error=0.8423\n",
      "[flaml.automl: 01-24 01:55:55] {2437} INFO - iteration 79, current learner xgb_limitdepth\n",
      "[flaml.automl: 01-24 01:55:55] {2597} INFO -  at 35.8s,\testimator xgb_limitdepth's best error=0.9462,\tbest estimator lgbm's best error=0.8423\n",
      "[flaml.automl: 01-24 01:55:55] {2437} INFO - iteration 80, current learner lgbm\n",
      "[flaml.automl: 01-24 01:55:56] {2597} INFO -  at 36.0s,\testimator lgbm's best error=0.8423,\tbest estimator lgbm's best error=0.8423\n",
      "[flaml.automl: 01-24 01:55:56] {2437} INFO - iteration 81, current learner lgbm\n",
      "[flaml.automl: 01-24 01:55:58] {2597} INFO -  at 38.3s,\testimator lgbm's best error=0.8358,\tbest estimator lgbm's best error=0.8358\n",
      "[flaml.automl: 01-24 01:55:58] {2437} INFO - iteration 82, current learner xgb_limitdepth\n",
      "[flaml.automl: 01-24 01:55:58] {2597} INFO -  at 38.4s,\testimator xgb_limitdepth's best error=0.9462,\tbest estimator lgbm's best error=0.8358\n",
      "[flaml.automl: 01-24 01:55:58] {2437} INFO - iteration 83, current learner lgbm\n",
      "[flaml.automl: 01-24 01:56:01] {2597} INFO -  at 41.1s,\testimator lgbm's best error=0.8281,\tbest estimator lgbm's best error=0.8281\n",
      "[flaml.automl: 01-24 01:56:01] {2437} INFO - iteration 84, current learner xgb_limitdepth\n",
      "[flaml.automl: 01-24 01:56:01] {2597} INFO -  at 41.2s,\testimator xgb_limitdepth's best error=0.9462,\tbest estimator lgbm's best error=0.8281\n",
      "[flaml.automl: 01-24 01:56:01] {2437} INFO - iteration 85, current learner xgb_limitdepth\n",
      "[flaml.automl: 01-24 01:56:01] {2597} INFO -  at 41.3s,\testimator xgb_limitdepth's best error=0.9462,\tbest estimator lgbm's best error=0.8281\n",
      "[flaml.automl: 01-24 01:56:01] {2437} INFO - iteration 86, current learner xgb_limitdepth\n",
      "[flaml.automl: 01-24 01:56:01] {2597} INFO -  at 41.3s,\testimator xgb_limitdepth's best error=0.9462,\tbest estimator lgbm's best error=0.8281\n",
      "[flaml.automl: 01-24 01:56:01] {2437} INFO - iteration 87, current learner catboost\n",
      "[flaml.automl: 01-24 01:56:01] {2597} INFO -  at 41.7s,\testimator catboost's best error=0.9346,\tbest estimator lgbm's best error=0.8281\n",
      "[flaml.automl: 01-24 01:56:01] {2437} INFO - iteration 88, current learner xgb_limitdepth\n",
      "[flaml.automl: 01-24 01:56:01] {2597} INFO -  at 41.8s,\testimator xgb_limitdepth's best error=0.9413,\tbest estimator lgbm's best error=0.8281\n",
      "[flaml.automl: 01-24 01:56:01] {2437} INFO - iteration 89, current learner lgbm\n",
      "[flaml.automl: 01-24 01:56:09] {2597} INFO -  at 49.5s,\testimator lgbm's best error=0.8281,\tbest estimator lgbm's best error=0.8281\n",
      "[flaml.automl: 01-24 01:56:09] {2437} INFO - iteration 90, current learner lgbm\n",
      "[flaml.automl: 01-24 01:56:12] {2597} INFO -  at 51.9s,\testimator lgbm's best error=0.8281,\tbest estimator lgbm's best error=0.8281\n",
      "[flaml.automl: 01-24 01:56:12] {2437} INFO - iteration 91, current learner extra_tree\n",
      "[flaml.automl: 01-24 01:56:12] {2597} INFO -  at 52.4s,\testimator extra_tree's best error=0.8450,\tbest estimator lgbm's best error=0.8281\n",
      "[flaml.automl: 01-24 01:56:12] {2437} INFO - iteration 92, current learner lgbm\n",
      "[flaml.automl: 01-24 01:56:18] {2597} INFO -  at 58.2s,\testimator lgbm's best error=0.8281,\tbest estimator lgbm's best error=0.8281\n",
      "[flaml.automl: 01-24 01:56:18] {2437} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl: 01-24 01:56:18] {2597} INFO -  at 58.2s,\testimator xgb_limitdepth's best error=0.9413,\tbest estimator lgbm's best error=0.8281\n",
      "[flaml.automl: 01-24 01:56:18] {2437} INFO - iteration 94, current learner catboost\n",
      "[flaml.automl: 01-24 01:56:18] {2597} INFO -  at 58.5s,\testimator catboost's best error=0.9346,\tbest estimator lgbm's best error=0.8281\n",
      "[flaml.automl: 01-24 01:56:18] {2437} INFO - iteration 95, current learner catboost\n",
      "[flaml.automl: 01-24 01:56:18] {2597} INFO -  at 58.8s,\testimator catboost's best error=0.9346,\tbest estimator lgbm's best error=0.8281\n",
      "[flaml.automl: 01-24 01:56:18] {2437} INFO - iteration 96, current learner rf\n",
      "[flaml.automl: 01-24 01:56:19] {2597} INFO -  at 59.3s,\testimator rf's best error=0.9421,\tbest estimator lgbm's best error=0.8281\n",
      "[flaml.automl: 01-24 01:56:19] {2437} INFO - iteration 97, current learner rf\n",
      "[flaml.automl: 01-24 01:56:20] {2597} INFO -  at 60.0s,\testimator rf's best error=0.9249,\tbest estimator lgbm's best error=0.8281\n",
      "[flaml.automl: 01-24 01:56:27] {2815} INFO - retrain lgbm for 7.6s\n",
      "[flaml.automl: 01-24 01:56:27] {2822} INFO - retrained model: LGBMRegressor(colsample_bytree=0.7487849262478875,\n",
      "              learning_rate=0.04342010918686734, max_bin=1023,\n",
      "              min_child_samples=3, n_estimators=76, num_leaves=407,\n",
      "              reg_alpha=0.030881405632915155, reg_lambda=0.9528325481378128,\n",
      "              verbose=-1)\n",
      "[flaml.automl: 01-24 01:56:27] {2199} INFO - fit succeeded\n",
      "[flaml.automl: 01-24 01:56:27] {2200} INFO - Time taken to find the best model: 41.104084491729736\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "\n",
    "# Initialize an AutoML instance\n",
    "automl = AutoML()\n",
    "# Specify automl goal and constraint\n",
    "automl_settings = {\n",
    "    \"time_budget\": 60,  # in seconds\n",
    "    \"metric\": 'r2',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": \"my.log\",\n",
    "}\n",
    "# Train with labeled input data\n",
    "automl.fit(X_train=X_train, y_train=y_train,\n",
    "           **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2  : 0.18148587857937692\n",
      "MAE : 0.43112686705864595\n",
      "MSE: 0.4776119625929101\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import  r2_score, mean_absolute_error , mean_squared_error\n",
    "print(f\"R2  : {r2_score(y_test, y_pred)}\")\n",
    "print(f\"MAE : {mean_absolute_error(y_test, y_pred)}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishna/miniconda3/envs/interactive-learning/lib/python3.8/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/krishna/miniconda3/envs/interactive-learning/lib/python3.8/site-packages/seaborn/distributions.py:2103: FutureWarning: The `axis` variable is no longer used and will be removed. Instead, assign variables directly to `x` or `y`.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/krishna/miniconda3/envs/interactive-learning/lib/python3.8/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/krishna/miniconda3/envs/interactive-learning/lib/python3.8/site-packages/seaborn/distributions.py:2103: FutureWarning: The `axis` variable is no longer used and will be removed. Instead, assign variables directly to `x` or `y`.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Normal Regression')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(y_test, hist=False, rug=True)\n",
    "sns.distplot(y_pred, hist=False, rug=True)\n",
    "plt.title(\"Normal Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b49589068baa6bec98c3349fdcd559e038c68bae5a4c5a7d44d7dd6cd95a33f2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('interactive-learning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
