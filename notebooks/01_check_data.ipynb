{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import pickle\n",
    "from feature_extractor import FeatureExtractor\n",
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import json\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "BASE_URL = \"https://benchmarking-scoring.aixplain.io/\"\n",
    "headers = {\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "def clean_target(text):\n",
    "    return text.replace(\"<v>\", \"\").replace(\"</v>\", \"\")\n",
    "\n",
    "def get_scores(source, target):\n",
    "    input_payload = {\n",
    "            \"input\": f'[\"{source}\"]',\n",
    "            \"output\": f'[\"{target}\"]',\n",
    "            \"refs\": \"\",\n",
    "            \"mode\": \"string\",\n",
    "            \"data_uri\": \"string\",\n",
    "            \"metric_name\": \"string\"\n",
    "            }\n",
    "    tmp_response = requests.request(\"POST\", BASE_URL+\"startasynctranslationscores\", headers=headers, data=json.dumps(input_payload))\n",
    "    tmp_response = tmp_response.json()\n",
    "    if \"request_id\" in tmp_response:\n",
    "      req_id = tmp_response[\"request_id\"]\n",
    "      get_score_payload = {\n",
    "      \"request_id\": f\"{req_id}\"\n",
    "      }\n",
    "    else:\n",
    "      raise ValueError(\"Error in the Scoring\")\n",
    "    while True :\n",
    "      sleep(0.05)\n",
    "      scores_response = requests.request(\"POST\", BASE_URL+\"getscores\", headers=headers, data=json.dumps(get_score_payload))\n",
    "      scores_response = scores_response.json() \n",
    "      if scores_response['completed']:\n",
    "          break\n",
    "    scores = scores_response['data']\n",
    "    clsss = scores['CLSSS']\n",
    "    comet = [scores['COMET_QE, cased, punctuated'], scores['COMET_QE, cased, not punctuated'],  scores['COMET_QE, uncased, punctuated'], scores['COMET_QE, uncased, not punctuated']]\n",
    "    comet = [float(_) for _ in comet]\n",
    "    return comet + [clsss]\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2020 = pd.read_csv(\"./wmt-mqm-human-evaluation/newstest2020/ende/mqm_newstest2020_ende.tsv\", sep=\"\\t\")\n",
    "df_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = FeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for source_text, subset in df_2020.groupby(\"source\"):\n",
    "    source_features = fe([source_text], \"en\")\n",
    "    for i,row in tqdm(subset.iterrows(), total = subset.shape[0]):\n",
    "        sample_id = format(i, '08d')\n",
    "        if not os.path.exists(f\"./data/{sample_id}.pkl\"):\n",
    "            target_text = clean_target(row.target)\n",
    "            target_features = fe([target_text], \"de\")\n",
    "            sample = {\n",
    "                    \"id\": i,\n",
    "                    \"source_features\": source_features,\n",
    "                    \"target_features\": target_features,\n",
    "                    \"target-source\": (target_features - source_features),\n",
    "                    \"category\": row.category,\n",
    "                    \"severity\": row.severity,\n",
    "                    \"commet_qe_clsss\": get_scores(source_text, target_text),\n",
    "                }\n",
    "            \n",
    "            with open(f\"./data/{sample_id}.pkl\", \"wb\") as tf:\n",
    "                pickle.dump(sample,tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b49589068baa6bec98c3349fdcd559e038c68bae5a4c5a7d44d7dd6cd95a33f2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('interactive-learning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
